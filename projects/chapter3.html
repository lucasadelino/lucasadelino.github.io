<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.2.1" /><meta property="og:title" content="Chapter 3 - N-gram Sentence Generator" /><meta property="og:locale" content="en" /><meta name="description" content="Homepage of Lucas Adelino, graduate student in Computational Linguistics." /><meta property="og:description" content="Homepage of Lucas Adelino, graduate student in Computational Linguistics." /><link rel="canonical" href="https://www.lucasadelino.com/projects/chapter3.html" /><meta property="og:url" content="https://www.lucasadelino.com/projects/chapter3.html" /><meta property="og:site_name" content="Lucas Adelino" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Chapter 3 - N-gram Sentence Generator" /><meta name="twitter:site" content="@lcsadelino" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"description":"Homepage of Lucas Adelino, graduate student in Computational Linguistics.","url":"https://www.lucasadelino.com/projects/chapter3.html","@type":"WebPage","headline":"Chapter 3 - N-gram Sentence Generator","@context":"https://schema.org"}</script><title>Chapter 3 - N-gram Sentence Generator | Lucas Adelino</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Lucas Adelino"><meta name="application-name" content="Lucas Adelino"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en">
<div class="profile-wrapper text-center">
<div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/lucas_avatar.jpeg" alt="avatar" onerror="this.style.display='none'"> </a>
</div>
<div class="site-title mt-3"> <a href="/">Lucas Adelino</a>
</div>
<div class="site-subtitle font-italic">Computational Linguistics Graduate Student</div>
</div>
<ul class="w-100">
<li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a>
</li>
<li class="nav-item"> <a href="/projects/" class="nav-link"> <i class="fa-fw fas fa-code ml-xl-3 mr-xl-3 unloaded"></i> <span>PROJECTS</span> </a>
</li>
<li class="nav-item"> <a href="/experience/" class="nav-link"> <i class="fa-fw fas fa-briefcase ml-xl-3 mr-xl-3 unloaded"></i> <span>EXPERIENCE</span> </a>
</li>
<li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a>
</li>
</ul>
<div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/lucasadelino" aria-label="github" class="order-3" target="_blank" rel="noopener noreferrer"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/lcsadelino" aria-label="twitter" class="order-4" target="_blank" rel="noopener noreferrer"> <i class="fab fa-twitter"></i> </a> <a href="javascript:location.href%20=%20'mailto:'%20+%20%5B'lcsadelino','gmail.com'%5D.join('@')" aria-label="email" class="order-5"> <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6"> <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span>
</div>
</div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span> <a href="/projects"> Projects </a> </span> <span>Chapter 3 - N-gram Sentence Generator</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div>
</div></div><div id="main-wrapper">
<div id="main">
<div class="row">
<div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4">
<h1 data-toc-skip>Chapter 3 - N-gram Sentence Generator</h1>
<div class="post-meta text-muted d-flex flex-column"><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2559 words">14 min read</span>
</div></div>
<div class="post-content">
<h2 id="what-it-is">What it is</h2>
<p>A <a href="https://twitter.com/assis_bot" target="_blank" rel="noopener noreferrer">bot</a> that uses an n-gram language model trained on the <a href="http://machado.byu.edu" target="_blank" rel="noopener noreferrer">Machado de Assis Digital Corpus</a> to generate random sentences.</p>
<h2 id="the-setup">The setup</h2>
<p><a href="https://web.stanford.edu/~jurafsky/slp3/3.pdf" target="_blank" rel="noopener noreferrer">Chapter 3 of Jurafsky and Martin</a> introduces the reader to n-gram language models. The exercises in chapter prompt the reader to write a program to compute unsmoothed unigrams and bigrams, and to add an option to that program to generate random sentences. As opposed to the <a href="/projects/chapter2.html">previous chapter</a>, this chapter does not provide the algorithm for implementing n-gram models (though it does provide formulas for calculating n-gram probabilities), which meant I would have to design the algorithm myself. I also thought it would be nice to try to compute any <em>n</em>-gram, not just unigrams and bigrams.</p>
<p>I was particularly inspired by the following example, which the authors used to show how higher order n-grams perform better (in terms of modeling the corpus on which it was trained):</p>
<p><img data-proofer-ignore data-src="/assets/higherngrams.PNG" alt="higherngrams.PNG"></p>
<p><a href="https://web.stanford.edu/~jurafsky/slp3/3.pdf#figure.3.4" target="_blank" rel="noopener noreferrer"><em>Jurafsky &amp; Martin (2021), p. 11</em></a></p>
<p>I thought that was the coolest thing I’d seen while learning NLP so far. I wanted to implement a similar bot, but I wanted my bot to model a Brazilian author. Machado de Assis was my first choice because his works are in the public domain and after some searching I found the <a href="http://machado.byu.edu" target="_blank" rel="noopener noreferrer">Machado the Assis Digital Corpus Project</a> from Brigham Young University, which perfectly suited this project.</p>
<h2 id="the-process">The process</h2>
<h3 id="challenge-1-sentence-segmentation-and-tokenization">Challenge #1: Sentence segmentation and tokenization</h3>
<p>Before I could even start thinking about the design of my n-gram algorithm, I first had to consider how I would approach sentence segmentation and tokenization. I could (and definitely would, if this were a professional project!) use an established tokenizer (like, say, <a href="http://www.nltk.org/" target="_blank" rel="noopener noreferrer">NLTK</a>’s), but since this was a learning project I thought it would be interesting to write my own (very crude) segmenter and tokenizer using regular expressions.</p>
<p>For sentence segmentation, I decided to use periods, question marks, and exclamation marks as sentence delimiters. The segmenter basically returns a list of all matches of the regex below:</p>
<div class="language-python highlighter-rouge">
<div class="code-header"> <span text-data=" Python "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button>
</div>
<div class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td>
<td class="rouge-code"><pre><span class="c1"># Matches everything before a period, question mark, or exclamation mark.
</span><span class="n">sentence_regex</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="sa">r</span><span class="s">'(\S(?:.+?)[\.\?!]+)'</span><span class="p">)</span>
</pre></td>
</tr></tbody></table></code></div>
</div>
<p>For tokenization, I wanted to have the option of either counting or not counting punctuation marks as tokens. I wrote a regex for each case and added a parameter in the function to signal which one to use. Before it returns, the tokenizer converts all tokens to lowercase:</p>
<div class="language-python highlighter-rouge">
<div class="code-header"> <span text-data=" Python "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button>
</div>
<div class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
</pre></td>
<td class="rouge-code"><pre><span class="c1"># Matches either a sequence of word characters or a punctuation mark
</span><span class="n">token_regex</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="sa">r</span><span class="s">'(\w+|[“”":;\'-\.\?!,]+)'</span><span class="p">,</span> <span class="n">re</span><span class="p">.</span><span class="n">UNICODE</span><span class="p">)</span>

<span class="c1"># Matches a sequence of alphabetic characters
</span><span class="n">word_regex</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="sa">r</span><span class="s">'(\w+)'</span><span class="p">,</span> <span class="n">re</span><span class="p">.</span><span class="n">UNICODE</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">punctuation</span> <span class="o">=</span> <span class="bp">True</span><span class="p">):</span>
    <span class="n">token_list</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">text</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">punctuation</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>
            <span class="n">token_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">token_regex</span><span class="p">.</span><span class="n">findall</span><span class="p">(</span><span class="n">sentence</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">token_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">word_regex</span><span class="p">.</span><span class="n">findall</span><span class="p">(</span><span class="n">sentence</span><span class="p">))</span>
    
    <span class="c1"># Case fold all words to lowercase
</span>    <span class="k">for</span> <span class="n">each_list</span> <span class="ow">in</span> <span class="n">token_list</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">each_list</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">word</span><span class="p">.</span><span class="n">isupper</span><span class="p">()</span> <span class="ow">or</span> <span class="n">word</span><span class="p">.</span><span class="n">istitle</span><span class="p">():</span>
                <span class="n">each_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span><span class="p">.</span><span class="n">lower</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">token_list</span>
</pre></td>
</tr></tbody></table></code></div>
</div>
<p>Note that this tokenizer doesn’t do a great job of parsing clitic contractions (as in <em>don’t</em>), but since Portuguese those are comparatively rarer in Portuguese, it gets the job done.</p>
<p>Now that I knew exactly what my tokenizer would return (a list of lists), I could start thinking about my n-gram algorithm.</p>
<h3 id="challenge-2-designing-the-n-gram-algorithm">Challenge #2: Designing the n-gram algorithm</h3>
<p>Before writing any code, I tried to consider all the steps necessary to implement the n-gram algorithm. For a given list (of lists) of tokens, the program would:</p>
<ol>
<li>Add sentence start <code class="language-plaintext highlighter-rouge">&lt;s&gt;</code> and end <code class="language-plaintext highlighter-rouge">&lt;/s&gt;</code> markers to each list of characters</li>
<li>Count the frequency of n-grams</li>
<li>Count the frequency of (n-1)-grams</li>
<li>Use steps 2 and 3 to calculate n-gram probabilities for all n-grams in the list.</li>
</ol>
<p>Let’s look at how to approach each of these steps.</p>
<h4 id="add-sentence-start-s-and-end-s-markers">Add sentence start &lt;s&gt; and end &lt;/s&gt; markers</h4>
<p>This step was relatively straightforward. For the probability distribution to work, we need to add $n - 1$ sentence start and end markers to our sentences. For instance, so for calculating trigrams, we would have: <code class="language-plaintext highlighter-rouge">&lt;s&gt; &lt;s&gt; an example sentence &lt;/s&gt; &lt;/s&gt;</code>. We can write the algorithm as such:</p>
<div class="language-python highlighter-rouge">
<div class="code-header"> <span text-data=" Python "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button>
</div>
<div class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td>
<td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>

<span class="k">def</span> <span class="nf">add_markers</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">token_list</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">token_list</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">token_list</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">token_list</span><span class="p">):</span>
            <span class="n">token_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">([</span><span class="s">'&lt;s&gt;'</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="n">sentence</span> <span class="o">+</span> <span class="p">([</span><span class="s">'&lt;/s&gt;'</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

		<span class="k">return</span> <span class="n">token_list</span>
</pre></td>
</tr></tbody></table></code></div>
</div>
<p>Our list of tokens passed as argument (token_list) is deep copied here to avoid changing it directly, since lists are mutable data types in Python.</p>
<h4 id="count-the-frequency-of-n-grams">Count the frequency of n-grams</h4>
<p>The idea here is also simple: first, let’s create a dictionary to contain our n-grams and their frequency counts. Then, we’ll look at each n-gram in our lists of tokens. We’ll add this n-gram to our dictionary if it isn’t already there (using <code class="language-plaintext highlighter-rouge">setdefault()</code>) and increase it’s frequency count by 1.</p>
<p>But there’s a small hitch: we want this to work for <em>any</em> \(n\), which means we first have to form n-grams using whatever \(n\) given. I knew I’d have to iterate over a list of tokens, but how would I set the parameters so that it worked for any \(n\)? Inspired by <a href="https://youtu.be/XYi2-LPrwm4?t=266" target="_blank" rel="noopener noreferrer">this video</a> (which I came across while studying the <a href="/projects/chapter2.html">minimum edit distance algorithm</a>, my approach was to use two pointers (which we’ll call \(i\) and \(p\)) to mark where we are in our list of tokens. We can use them to iterate over the preceding words and join them together to form an n-gram.</p>
<p>To figure out exactly how this would work, I drew two cases on paper: one for a trigram and another for a 4-gram. Let’s look at the trigram $(n = 3)$ first. In the first iteration, we would have:</p>
<div align="center"><div class="table-wrapper"><table>
<thead><tr>
<th>&lt;s&gt;</th>
<th>&lt;s&gt;</th>
<th>she</th>
<th>set</th>
<th>out</th>
<th>&lt;/s&gt;</th>
<th>&lt;/s&gt;</th>
</tr></thead>
<tbody>
<tr>
<td>0</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>5</td>
<td>6</td>
</tr>
<tr>
<td>p</td>
<td></td>
<td>i</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table></div></div>
<p>\(p\) would then iterate until it met \(i\), which would form the trigram <code class="language-plaintext highlighter-rouge">&lt;s&gt; &lt;s&gt; she</code>. Then, \(p\) would return to it’s starting position and both \(p\) and \(i\) would increase by $1$, so that we can form the next trigram (<code class="language-plaintext highlighter-rouge">&lt;s&gt; she set</code>).</p>
<p>For our 4-gram $(n = 4)$, in our first iteration would have:</p>
<div align="center"><div class="table-wrapper"><table>
<thead><tr>
<th>&lt;s&gt;</th>
<th>&lt;s&gt;</th>
<th>&lt;s&gt;</th>
<th>she</th>
<th>set</th>
<th>out</th>
<th>&lt;/s&gt;</th>
<th>&lt;/s&gt;</th>
<th>&lt;/s&gt;</th>
</tr></thead>
<tbody>
<tr>
<td>0</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>5</td>
<td>6</td>
<td>7</td>
<td>8</td>
</tr>
<tr>
<td>p</td>
<td></td>
<td></td>
<td>i</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table></div></div>
<p>We can generalize from the above to get the starting values of \(i\) and \(p\):</p>
<ul>
<li>\(i\) starts at $2$ when $n = 3$, and at $3$ when $n = 4$. Therefore, \(i\) always starts at $n - 1$.</li>
<li>\(p\) starts $(n - 1)$ steps behind \(i\). Therefore, \(p\) always starts at $i - (n - 1)$</li>
</ul>
<p>We’re almost ready to write our function! We just need one more thing: a parameter that tells the function to add (or not) <code class="language-plaintext highlighter-rouge">&lt;s&gt;</code> and <code class="language-plaintext highlighter-rouge">&lt;/s&gt;</code> markers to the list of tokens before forming and counting n-grams. The final result looks like this:</p>
<div class="language-python highlighter-rouge">
<div class="code-header"> <span text-data=" Python "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button>
</div>
<div class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre></td>
<td class="rouge-code"><pre><span class="k">def</span> <span class="nf">ngram_count</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">token_list</span><span class="p">,</span> <span class="n">markers</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>

<span class="k">if</span> <span class="n">markers</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">token_list</span> <span class="o">=</span> <span class="n">add_markers</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">token_list</span><span class="p">)</span>

<span class="n">ngram_dict</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">token_list</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">((</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)):</span>
            <span class="c1"># Look at last (i - (n-1)) words for concatenation
</span>            <span class="n">p</span> <span class="o">=</span> <span class="n">i</span> <span class="o">-</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="c1"># Form an ngram by concatenating last (i - (n-1)) words, up to i
</span>            <span class="n">ngram</span> <span class="o">=</span> <span class="s">''</span>
            <span class="k">while</span> <span class="n">pointer</span> <span class="o">&lt;=</span> <span class="n">i</span><span class="p">:</span> 
                <span class="n">ngram</span> <span class="o">+=</span> <span class="n">sentence</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">+</span> <span class="s">' '</span>
                <span class="n">pointer</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="c1"># Add ngram to dict
</span>            <span class="n">ngram_dict</span><span class="p">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">ngram</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">ngram_dict</span><span class="p">[</span><span class="n">ngram</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    
    <span class="k">return</span> <span class="n">ngram_dict</span>
</pre></td>
</tr></tbody></table></code></div>
</div>
<h4 id="calculate-probabilities">Calculate probabilities</h4>
<p>Now that we can count n-grams, it’s time to start working on a function to calculate probabilities. Again, the basic steps are:</p>
<ol>
<li>Count the frequency of n-grams</li>
<li>Count the frequency of (n-1)-grams</li>
<li>Use the above to calculate probability</li>
</ol>
<p>We need to do this for all n-grams in a list of tokens. Once more, the idea is simple, but we need to pay attention to a couple of things<sup id="fnref:footnote" role="doc-noteref"><a href="#fn:footnote" class="footnote" rel="footnote">1</a></sup>:</p>
<ul>
<li>We must add the markers to our list of tokens <strong>only once</strong>. Forgetting this would add extra markers to our list and throw off the computation. We’ll manually add the markers using <code class="language-plaintext highlighter-rouge">add_markers()</code> and remember to set <code class="language-plaintext highlighter-rouge">markers=False</code> whenever we call <code class="language-plaintext highlighter-rouge">ngram_count()</code>.</li>
<li>We need to consider what to do for unigrams $(n = 1)$. In this case, we need to divide the how many times the unigram appears by the total amount of tokens. Let’s create a short function to count the number of tokens in a list:</li>
</ul>
<div class="language-python highlighter-rouge">
<div class="code-header"> <span text-data=" Python "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button>
</div>
<div class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td>
<td class="rouge-code"><pre><span class="k">def</span> <span class="nf">get_token_count</span><span class="p">(</span><span class="n">token_list</span><span class="p">):</span>

    <span class="n">token_count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">ngram_count</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">token_list</span><span class="p">).</span><span class="n">values</span><span class="p">():</span>
        <span class="n">token_count</span> <span class="o">+=</span> <span class="n">value</span>

    <span class="k">return</span> <span class="n">token_count</span>
</pre></td>
</tr></tbody></table></code></div>
</div>
<p>Now we can write our function:</p>
<div class="language-python highlighter-rouge">
<div class="code-header"> <span text-data=" Python "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button>
</div>
<div class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
</pre></td>
<td class="rouge-code"><pre><span class="k">def</span> <span class="nf">ngram_prob</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">token_list</span><span class="p">):</span>

    <span class="n">ngram_prob</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="c1"># Add markers
</span>    <span class="n">token_list</span> <span class="o">=</span> <span class="n">add_markers</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">token_list</span><span class="p">)</span>

    <span class="c1"># Get the counts of ngrams of the same n passed as argument
</span>    <span class="n">ngrams</span> <span class="o">=</span>  <span class="n">ngram_count</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">token_list</span><span class="p">,</span> <span class="n">markers</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="c1"># Get the count of lower-order ngram OR total number of tokens if n == 1
</span>    <span class="k">if</span> <span class="n">n</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">lower_ngrams</span> <span class="o">=</span>  <span class="n">ngram_count</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">token_list</span><span class="p">,</span> <span class="n">markers</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">lower_ngram_count</span> <span class="o">=</span> <span class="n">get_token_count</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">ngrams</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">n</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Lower order ngram = current ngram minus its last word
</span>            <span class="n">lower_ngram_key</span> <span class="o">=</span> <span class="n">key</span><span class="p">.</span><span class="n">rsplit</span><span class="p">(</span><span class="s">' '</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">lower_ngram_count</span> <span class="o">=</span> <span class="n">lower_ngrams</span><span class="p">[</span><span class="n">lower_ngram_key</span><span class="p">]</span>
        <span class="n">ngram_prob</span><span class="p">.</span><span class="n">update</span><span class="p">({</span><span class="n">key</span><span class="p">:</span> <span class="p">(</span><span class="n">count</span> <span class="o">/</span> <span class="n">lower_ngram_count</span><span class="p">)})</span>
    
    <span class="k">return</span> <span class="n">ngram_prob</span>
</pre></td>
</tr></tbody></table></code></div>
</div>
<p>We’re not using log probabilities here to make the next step a little easier.</p>
<h3 id="challenge-3-generating-sentences">Challenge #3: Generating sentences</h3>
<p>Now that our program can count n-gram probabilities, we can use the <code class="language-plaintext highlighter-rouge">ngram_prob</code> dictionary the function above returns to generate sentences. The idea for this is not as straightforward as the previous functions, so let’s take it piece by piece.</p>
<p>Before we begin, let’s get the value of our $n$. We’re getting a dictionary of n-gram probabilities, so we don’t need to ask the user to manually type the $n$ when calling the function; we can get that from the dict:</p>
<div class="language-python highlighter-rouge">
<div class="code-header"> <span text-data=" Python "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button>
</div>
<div class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
</pre></td>
<td class="rouge-code"><pre><span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">ngram_probs</span><span class="p">.</span><span class="n">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">].</span><span class="n">split</span><span class="p">(</span><span class="s">' '</span><span class="p">))</span>
</pre></td>
</tr></tbody></table></code></div>
</div>
<h4 id="generating-the-first-n-gram">Generating the first n-gram</h4>
<p>The first thing we’ll need to do is choose our first n-gram. Since we’re starting a sentence, we must only consider n-grams that start that start with $n-1$ <code class="language-plaintext highlighter-rouge">&lt;s&gt;</code> markers:</p>
<div class="language-python highlighter-rouge">
<div class="code-header"> <span text-data=" Python "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button>
</div>
<div class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td>
<td class="rouge-code"><pre><span class="n">next_keys</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">next_values</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">ngram_probs</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">k</span><span class="p">.</span><span class="n">startswith</span><span class="p">((</span><span class="s">'&lt;s&gt; '</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)).</span><span class="n">rstrip</span><span class="p">()):</span>
        <span class="n">next_keys</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
        <span class="n">next_values</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="c1"># Choose ngram according to its probability
</span><span class="n">sentence</span> <span class="o">=</span> <span class="n">choices</span><span class="p">(</span><span class="n">next_keys</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">next_values</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</pre></td>
</tr></tbody></table></code></div>
</div>
<p>Note that we can only use <code class="language-plaintext highlighter-rouge">choices()</code> with <code class="language-plaintext highlighter-rouge">next_values</code> as weights because we didn’t use log probabilities in our <code class="language-plaintext highlighter-rouge">ngram_prob</code> function.</p>
<p>Let’s also take note of the last word in the n-gram we just generated:</p>
<div class="language-python highlighter-rouge">
<div class="code-header"> <span text-data=" Python "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button>
</div>
<div class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
</pre></td>
<td class="rouge-code"><pre><span class="n">last_word</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">.</span><span class="n">rsplit</span><span class="p">(</span><span class="s">' '</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
</pre></td>
</tr></tbody></table></code></div>
</div>
<h4 id="generating-remaining-n-grams">Generating remaining n-grams</h4>
<p>Now, let’s generate the rest of the sentence. The idea is to keep generating n-grams, using the last word of the n-gram we just got as the first word of the next n-gram. Let’s start with by taking note of n-grams whose first word == <code class="language-plaintext highlighter-rouge">last_word</code>:</p>
<div class="language-python highlighter-rouge">
<div class="code-header"> <span text-data=" Python "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button>
</div>
<div class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td>
<td class="rouge-code"><pre><span class="n">next_keys</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">next_values</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">ngram_probs</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">k</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">last_word</span><span class="p">):</span>
        <span class="n">next_keys</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
        <span class="n">next_values</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
</pre></td>
</tr></tbody></table></code></div>
</div>
<p>We’ll again choose an n-gram according to its probability. We’ll add it to the sentence <strong>without</strong> its first word (since it’s already in the sentence). To keep the loop going, we’ll again take note of the last word of the n-gram we chose:</p>
<div class="language-python highlighter-rouge">
<div class="code-header"> <span text-data=" Python "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button>
</div>
<div class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td>
<td class="rouge-code"><pre><span class="n">next_ngram</span> <span class="o">=</span> <span class="n">choices</span><span class="p">(</span><span class="n">next_keys</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">next_values</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">sentence</span> <span class="o">+=</span> <span class="s">' '</span> <span class="o">+</span> <span class="n">next_ngram</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">' '</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">last_word</span> <span class="o">=</span> <span class="n">next_ngram</span><span class="p">.</span><span class="n">rsplit</span><span class="p">(</span><span class="s">' '</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
</pre></td>
</tr></tbody></table></code></div>
</div>
<p>We’ll keep repeating this process until we generate an n-gram with a <code class="language-plaintext highlighter-rouge">&lt;/s&gt;</code> marker. If there are any <code class="language-plaintext highlighter-rouge">&lt;/s&gt;</code> markers missing when the loop stops, but we can add them to our sentence (or, if you want the output to not contain any <code class="language-plaintext highlighter-rouge">&lt;s&gt;</code> and <code class="language-plaintext highlighter-rouge">&lt;/s&gt;</code> markers, you can tweak the code below to do so):</p>
<div class="language-python highlighter-rouge">
<div class="code-header"> <span text-data=" Python "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button>
</div>
<div class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td>
<td class="rouge-code"><pre><span class="n">endmarker_regex</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="sa">r</span><span class="s">'&lt;/s&gt;'</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">+=</span>  <span class="s">' &lt;/s&gt;'</span> <span class="o">*</span> <span class="p">((</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">endmarker_regex</span><span class="p">.</span><span class="n">findall</span><span class="p">(</span><span class="n">sentence</span><span class="p">)))</span>
</pre></td>
</tr></tbody></table></code></div>
</div>
<p>That’s it! Now, adding it all together:</p>
<div class="language-python highlighter-rouge">
<div class="code-header"> <span text-data=" Python "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button>
</div>
<div class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
</pre></td>
<td class="rouge-code"><pre><span class="c1"># Matches en dashes surrounded by word characters. Useful for PT-BR parsing
</span><span class="n">endmarker_regex</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="sa">r</span><span class="s">'&lt;/s&gt;'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">generate_sentence</span><span class="p">(</span><span class="n">ngram_probs</span><span class="p">):</span>
    <span class="c1"># Look at keys in ngram_probs to figure out what's the order of our ngrams
</span>    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">ngram_probs</span><span class="p">.</span><span class="n">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">].</span><span class="n">split</span><span class="p">(</span><span class="s">' '</span><span class="p">))</span>

    <span class="c1"># Look for 1st ngram. Consider only ngrams that start with n-1 &lt;s&gt; markers
</span>    <span class="n">next_keys</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">next_values</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">ngram_probs</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">k</span><span class="p">.</span><span class="n">startswith</span><span class="p">((</span><span class="s">'&lt;s&gt; '</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)).</span><span class="n">rstrip</span><span class="p">()):</span>
            <span class="n">next_keys</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
            <span class="n">next_values</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="c1"># Choose ngram according to its probability
</span>    <span class="n">sentence</span> <span class="o">=</span> <span class="n">choices</span><span class="p">(</span><span class="n">next_keys</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">next_values</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># Next ngram must start with the last word of this ngram
</span>    <span class="n">last_word</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">.</span><span class="n">rsplit</span><span class="p">(</span><span class="s">' '</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="c1"># Keep generating sentences until we get an n-gram with an &lt;/s&gt; end marker 
</span>    <span class="c1"># Loop stops after the first &lt;/s&gt;; we'll add the remaining markers later 
</span>    <span class="k">while</span> <span class="s">'&lt;/s&gt;'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">last_word</span><span class="p">:</span>
        <span class="c1"># Look for next ngram.
</span>        <span class="n">next_keys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">next_values</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">ngram_probs</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">k</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">last_word</span><span class="p">):</span>
                <span class="n">next_keys</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                <span class="n">next_values</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        
        <span class="c1"># Choose ngram. Don't add first word since it's already in the sentence
</span>        <span class="n">next_ngram</span> <span class="o">=</span> <span class="n">choices</span><span class="p">(</span><span class="n">next_keys</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">next_values</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">sentence</span> <span class="o">+=</span> <span class="s">' '</span> <span class="o">+</span> <span class="n">next_ngram</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">' '</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">last_word</span> <span class="o">=</span> <span class="n">next_ngram</span><span class="p">.</span><span class="n">rsplit</span><span class="p">(</span><span class="s">' '</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># Add missing sentence end markers
</span>    <span class="n">sentence</span> <span class="o">+=</span>  <span class="s">' &lt;/s&gt;'</span> <span class="o">*</span> <span class="p">((</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">endmarker_regex</span><span class="p">.</span><span class="n">findall</span><span class="p">(</span><span class="n">sentence</span><span class="p">)))</span>

    <span class="k">return</span> <span class="n">sentence</span>
</pre></td>
</tr></tbody></table></code></div>
</div>
<p>Now all we need to do is generate a dictionary of n-gram probabilities from the entire Machado de Assis corpus, and use that dictionary to generate sentences! Here’s the <a href="https://t.co/YCUmayR2cx?amp=1" target="_blank" rel="noopener noreferrer">final version of the code</a>, including everything described so far.</p>
<h3 id="further-improvement">Further Improvement</h3>
<p>In the current version of the program, the process of generating n-grams is not particularly efficient: every time we generate a piece of the n-gram, we need to traverse the entire dictionary of n-gram probabilities to find n-gram candidates that start with the appropriate word. One potential way of improving this code is to use a tree rather than a dictionary to contain n-gram probabilities. Each node of the tree would be a unigram, with its children being the words that come after it, and their parent the word that comes before. This would reduce the amount of dictionary accesses since n-grams that start with the same word (like <code class="language-plaintext highlighter-rouge">&lt;s&gt; she set</code> and <code class="language-plaintext highlighter-rouge">&lt;s&gt; she did</code>) would be grouped closer together.</p>
<p>I’m currently taking an algorithms and data structures course on Coursera, and I’m about to start studying trees in more detail. As soon as I’m more comfortable with them, I will come back and rewrite the code accordingly!</p>
<div class="footnotes" role="doc-endnotes"><ol><li id="fn:footnote" role="doc-endnote"><p>It’s worth nothing that, as one can see by the <a href="https://github.com/lucasadelino/Learning-Compling/commits/main/Textbooks/Speech%20and%20Language%20Processing%20(Jurafsky%2C%20Martin)/Chapter%203%20-%20N-gram%20Language%20Models/ngram.py" target="_blank" rel="noopener noreferrer">commit history of this project</a>, I didn’t realize these things at first! In particular, I was unsure when to add markers in the program. My <a href="https://github.com/lucasadelino/Learning-Compling/commit/1666dda9ac84e0d4861075d43d6809c0cb340c0a#diff-8fffd6dea253d4cfd6e5c12dc954dbf9ef2f31dd2a18fa5572fa1ffaa7700621" target="_blank" rel="noopener noreferrer">first instinct</a> was to do it inside <code class="language-plaintext highlighter-rouge">tokenize()</code>. That works, but it requires the user to specify the value of $n$ twice (once when calling <code class="language-plaintext highlighter-rouge">tokenize()</code> and once when calling <code class="language-plaintext highlighter-rouge">ngram_prob()</code>). I also <a href="https://github.com/lucasadelino/Learning-Compling/commit/98bf0bb41462fbe6e6e5ee6b63602fbb8f864bbc#diff-8fffd6dea253d4cfd6e5c12dc954dbf9ef2f31dd2a18fa5572fa1ffaa7700621" target="_blank" rel="noopener noreferrer">tried to do it</a> inside <code class="language-plaintext highlighter-rouge">ngram_count()</code> automatically, which also works, but only because it modifies the list passed into it (since Python lists are mutable), which struck me as less then ideal. I eventually decided to create a separate function to add the markers, add a parameter to <code class="language-plaintext highlighter-rouge">ngram_count()</code> to make adding markers optional, and manually add markers in the <code class="language-plaintext highlighter-rouge">ngram_prob()</code>, which how it’s process described in the main text. <a href="#fnref:footnote" class="reversefootnote" role="doc-backlink">↩</a></p></li></ol></div>
</div>
<div class="post-tail-wrapper text-muted"><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2">
<div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank" rel="noopener noreferrer"> CC BY 4.0 </a> by the author.</div>
<div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Chapter%203%20-%20N-gram%20Sentence%20Generator%20-%20Lucas%20Adelino&amp;url=https://www.lucasadelino.com/projects/chapter3.html" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener noreferrer" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Chapter%203%20-%20N-gram%20Sentence%20Generator%20-%20Lucas%20Adelino&amp;u=https://www.lucasadelino.com/projects/chapter3.html" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener noreferrer" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Chapter%203%20-%20N-gram%20Sentence%20Generator%20-%20Lucas%20Adelino&amp;url=https://www.lucasadelino.com/projects/chapter3.html" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener noreferrer" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span>
</div>
</div></div>
</div></div>
<div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down">
<div class="access"></div>
<script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav>
</div>
</div>
</div>
<footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2024 <a href="https://twitter.com/lcsadelino" target="_blank" rel="noopener noreferrer">Lucas Adelino</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div></div></footer>
</div>
<div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content">
<div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4></div>
<div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
</div></div>
</div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://www.lucasadelino.com{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-4FN8XC8V4J"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-4FN8XC8V4J'); }); </script>
